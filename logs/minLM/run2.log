{'deploy': True, 'tag': 'minLM', 'run_name': 'run2', 'seed': 0, 'device': 'cuda:0', 'total_iters': 600000, 'data': {'bs': 32, 'tokenizer': 'openai-community/gpt2', 'subsample': 1.0, 'min_len': 0, 'nworkers': 2}, 'net': {'compile': True, 'vocab_size': 50258, 'context_size': 512, 'n_layer': 12, 'n_head': 12, 'n_embd': 1080, 'dropout': 0.0, 'bias': False}, 'optimizer': {'learning_rate': 0.0003, 'weight_decay': 0.1, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'grad_accumulation': 40, 'ignore_eos': False, 'use_scaler': True, 'warmup_iters': 0, 'decay_lr': True, 'min_lr': 3e-05}, 'log': {'eval_interval': 5000, 'log_interval': 500, 'save_interval': 50000}}
num decayed parameter tensors: 50, with 222,793,200 parameters
num non-decayed parameter tensors: 25, with 27,000 parameters
using fused AdamW: True
Iter 0 | Perplexity: 57534.89453125
Epoch 0.0
Iter 0 | LR: 0.0003 | Loss: inf
Iter 500 | LR: 0.0002999995373625579 | Loss: 4.33106505960226
Iter 1000 | LR: 0.00029999814945340256 | Loss: 1.984347048401834
Iter 1500 | LR: 0.0002999958362820466 | Loss: 1.9295388098061088
Iter 2000 | LR: 0.0002999925978643441 | Loss: 1.9285260424017905
Iter 2500 | LR: 0.0002999884342224909 | Loss: 1.9112696874141686
Iter 3000 | LR: 0.00029998334538502416 | Loss: 1.9068046119809152
Iter 3500 | LR: 0.00029997733138682216 | Loss: 1.8788770967721948
Iter 4000 | LR: 0.0002999703922691041 | Loss: 1.8087200362980362
Iter 4500 | LR: 0.00029996252807943004 | Loss: 1.764950222969057
Iter 5000 | Perplexity: 702.6207275390625
Iter 5000 | LR: 0.0002999537388717002 | Loss: 1.7310203944146634
Iter 5500 | LR: 0.00029994402470615483 | Loss: 1.7053998030722137
Iter 6000 | LR: 0.00029993338564937377 | Loss: 1.6657404366135604
Iter 6500 | LR: 0.00029992182177427583 | Loss: 1.6340673534572112
Iter 7000 | LR: 0.00029990933316011853 | Loss: 1.6130651298165295
Iter 7500 | LR: 0.00029989591989249757 | Loss: 1.597042018771172
Iter 8000 | LR: 0.00029988158206334587 | Loss: 1.5697594234347358
Iter 8500 | LR: 0.0002998663197709333 | Loss: 1.5513446091115484
Iter 9000 | LR: 0.00029985013311986593 | Loss: 1.529548524469138
Iter 9500 | LR: 0.00029983302222108527 | Loss: 1.5213101173937305
Iter 10000 | Perplexity: 299.27020263671875
Iter 10000 | LR: 0.00029981498719186745 | Loss: 1.5064132517576214
Iter 10500 | LR: 0.00029979602815582263 | Loss: 1.4934482705593117
Iter 11000 | LR: 0.0002997761452428938 | Loss: 1.4805821216106427
Iter 11500 | LR: 0.00029975533858935633 | Loss: 1.4714934344589703
Iter 12000 | LR: 0.00029973360833781664 | Loss: 1.442673989236354
Iter 12500 | LR: 0.0002997109546372114 | Loss: 1.4556182304024707
Iter 13000 | LR: 0.0002996873776428067 | Loss: 1.4244513352215282
Iter 13500 | LR: 0.00029966287751619644 | Loss: 1.4109829099476345
Iter 14000 | LR: 0.0002996374544253018 | Loss: 1.4121571379899989
Iter 14500 | LR: 0.0002996111085443698 | Loss: 1.39931678265333
Iter 15000 | Perplexity: 174.74215698242188
Iter 15000 | LR: 0.00029958384005397226 | Loss: 1.383252350836993
Iter 15500 | LR: 0.0002995556491410042 | Loss: 1.3728891940414902
Iter 16000 | LR: 0.00029952653599868304 | Loss: 1.3498102194070816
Iter 16500 | LR: 0.00029949650082654707 | Loss: 1.3472000223398204
Iter 17000 | LR: 0.0002994655438304539 | Loss: 1.3284450882673264
Iter 17500 | LR: 0.0002994336652225793 | Loss: 1.3229317851364621
Iter 18000 | LR: 0.0002994008652214158 | Loss: 1.3023788906633842
Iter 18500 | LR: 0.0002993671440517708 | Loss: 1.3113701154291613
Iter 19000 | LR: 0.00029933250194476556 | Loss: 1.285526741594076
Iter 19500 | LR: 0.00029929693913783304 | Loss: 1.2861124214530002
Iter 20000 | Perplexity: 117.73754119873047
Iter 20000 | LR: 0.00029926045587471686 | Loss: 1.2773259483277781
Iter 20500 | LR: 0.00029922305240546917 | Loss: 1.2678406596183787
Iter 21000 | LR: 0.00029918472898644925 | Loss: 1.2644049473106864
Iter 21500 | LR: 0.0002991454858803214 | Loss: 1.2509791129827494
Iter 22000 | LR: 0.0002991053233560535 | Loss: 1.243215794861317
Iter 22500 | LR: 0.00029906424168891506 | Loss: 1.2233213716745375
Iter 23000 | LR: 0.00029902224116047513 | Loss: 1.217629520446061
Iter 23500 | LR: 0.0002989793220586007 | Loss: 1.2194856570661063
Iter 24000 | LR: 0.0002989354846774545 | Loss: 1.2133284053206437
Iter 24500 | LR: 0.00029889072931749296 | Loss: 1.19927229821682
Iter 25000 | Perplexity: 86.05795288085938
Iter 25000 | LR: 0.0002988450562854644 | Loss: 1.200621688961983
Iter 25500 | LR: 0.00029879846589440657 | Loss: 1.191852347850801
Iter 26000 | LR: 0.00029875095846364485 | Loss: 1.1745850682258603
Iter 26500 | LR: 0.00029870253431878987 | Loss: 1.1628311464190477
Epoch 1.0
Iter 27000 | LR: 0.0002986531937917352 | Loss: 1.171443372666836
Iter 27500 | LR: 0.0002986029372206555 | Loss: 1.1490635235607627
Iter 28000 | LR: 0.00029855176495000344 | Loss: 1.1398044250905508
Iter 28500 | LR: 0.0002984996773305081 | Loss: 1.1455183221399783
Iter 29000 | LR: 0.00029844667471917225 | Loss: 1.1378471875190743
Iter 29500 | LR: 0.0002983927574792698 | Loss: 1.1328621941804884
Iter 30000 | Perplexity: 69.14907836914062
Iter 30000 | LR: 0.0002983379259803436 | Loss: 1.1201645053923133
Iter 30500 | LR: 0.0002982821805982024 | Loss: 1.1227946564555158
Iter 31000 | LR: 0.00029822552171491893 | Loss: 1.1139368884265421
Iter 31500 | LR: 0.00029816794971882686 | Loss: 1.1024473811686046
Iter 32000 | LR: 0.00029810946500451814 | Loss: 1.1060689543187618
Iter 32500 | LR: 0.00029805006797284047 | Loss: 1.0911087070405476
Iter 33000 | LR: 0.0002979897590308944 | Loss: 1.088014624714852
Iter 33500 | LR: 0.0002979285385920308 | Loss: 1.0868846593797212
Iter 34000 | LR: 0.0002978664070758476 | Loss: 1.0680630360543737
Iter 34500 | LR: 0.00029780336490818735 | Loss: 1.0894293825328343
Iter 35000 | Perplexity: 56.228607177734375
Iter 35000 | LR: 0.0002977394125211339 | Loss: 1.0579301387071611
Iter 35500 | LR: 0.0002976745503530097 | Loss: 1.0709128668904302
Iter 36000 | LR: 0.000297608778848373 | Loss: 1.0636539605259894
Iter 36500 | LR: 0.00029754209845801407 | Loss: 1.0580641935765749
Iter 37000 | LR: 0.00029747450963895305 | Loss: 1.057947481274606
Iter 37500 | LR: 0.0002974060128544361 | Loss: 1.0442017236351964
Iter 38000 | LR: 0.00029733660857393245 | Loss: 1.0470274476706969
Iter 38500 | LR: 0.00029726629727313126 | Loss: 1.031309910416603
Iter 39000 | LR: 0.00029719507943393837 | Loss: 1.0377000473439695
Iter 39500 | LR: 0.00029712295554447284 | Loss: 1.0287446957081563
Iter 40000 | Perplexity: 48.349361419677734
Iter 40000 | LR: 0.0002970499260990637 | Loss: 1.016844013631344
Iter 40500 | LR: 0.00029697599159824676 | Loss: 1.0196702504158028
Iter 41000 | LR: 0.0002969011525487606 | Loss: 1.0217238807678224
Iter 41500 | LR: 0.00029682540946354376 | Loss: 1.0124487937986837
Iter 42000 | LR: 0.00029674876286173087 | Loss: 1.0085126647353175
Iter 42500 | LR: 0.0002966712132686492 | Loss: 1.0017420774698258
Iter 43000 | LR: 0.0002965927612158149 | Loss: 1.0034952619671818
Iter 43500 | LR: 0.00029651340724092966 | Loss: 1.0028035753965376
Iter 44000 | LR: 0.0002964331518878766 | Loss: 0.9969743086397652
Iter 44500 | LR: 0.00029635199570671704 | Loss: 0.9929362859576939
Iter 45000 | Perplexity: 42.4760627746582
Iter 45000 | LR: 0.0002962699392536863 | Loss: 0.9894455854594699
Iter 45500 | LR: 0.00029618698309119015 | Loss: 0.9864290173351759
Iter 46000 | LR: 0.00029610312778780083 | Loss: 0.9920499658584595
Iter 46500 | LR: 0.0002960183739182532 | Loss: 0.9959193475544449
Iter 47000 | LR: 0.0002959327220634408 | Loss: 0.9746631091833118
Iter 47500 | LR: 0.0002958461728104118 | Loss: 0.9777230481803425
Iter 48000 | LR: 0.0002957587267523652 | Loss: 0.97438929617405
Iter 48500 | LR: 0.00029567038448864637 | Loss: 0.969146328270435
Iter 49000 | LR: 0.0002955811466247433 | Loss: 0.9613521029055117
Iter 49500 | LR: 0.00029549101377228246 | Loss: 0.9731435570120812
Iter 50000 | Perplexity: 38.55497360229492
Iter 50000 | LR: 0.0002953999865490242 | Loss: 0.9651965679228309
Iter 50500 | LR: 0.00029530806557885895 | Loss: 0.9575582840293659
Iter 51000 | LR: 0.00029521525149180274 | Loss: 0.9580450502038003
Iter 51500 | LR: 0.0002951215449239929 | Loss: 0.9542927346378572
Iter 52000 | LR: 0.00029502694651768383 | Loss: 0.9629959577322003
Iter 52500 | LR: 0.00029493145692124234 | Loss: 0.947415016070009
Iter 53000 | LR: 0.00029483507678914353 | Loss: 0.94570586502552
Iter 53500 | LR: 0.0002947378067819659 | Loss: 0.9528057909011829
Epoch 2.0
Iter 54000 | LR: 0.0002946396475663873 | Loss: 0.9365865667164334
Iter 54500 | LR: 0.00029454059981517993 | Loss: 0.9280173519253734
Iter 55000 | Perplexity: 35.874332427978516
Iter 55000 | LR: 0.00029444066420720603 | Loss: 0.9205293963104482
Iter 55500 | LR: 0.00029433984142741306 | Loss: 0.9266285553574556
Iter 56000 | LR: 0.000294238132166829 | Loss: 0.9142118587344884
Iter 56500 | LR: 0.0002941355371225579 | Loss: 0.9217018201202157
Iter 57000 | LR: 0.0002940320569977745 | Loss: 0.9104628493636837
Iter 57500 | LR: 0.00029392769250172017 | Loss: 0.916751807779073
Iter 58000 | LR: 0.00029382244434969734 | Loss: 0.9192212612926957
Iter 58500 | LR: 0.00029371631326306514 | Loss: 0.9180544141679997
Iter 59000 | LR: 0.00029360929996923415 | Loss: 0.9063634252548218
Iter 59500 | LR: 0.00029350140520166144 | Loss: 0.9114423251152037
Iter 60000 | Perplexity: 33.61921691894531
Iter 60000 | LR: 0.0002933926296998457 | Loss: 0.9156512141227724
Iter 60500 | LR: 0.00029328297420932206 | Loss: 0.9160446478426458
Iter 61000 | LR: 0.00029317243948165703 | Loss: 0.9164765332639229
Iter 61500 | LR: 0.0002930610262744431 | Loss: 0.9062671469897032
Iter 62000 | LR: 0.00029294873535129403 | Loss: 0.9124701282382017
Iter 62500 | LR: 0.00029283556748183927 | Loss: 0.9010462856292731
Iter 63000 | LR: 0.0002927215234417186 | Loss: 0.9129582559317342
Iter 63500 | LR: 0.00029260660401257715 | Loss: 0.9057600663602345
Iter 64000 | LR: 0.0002924908099820599 | Loss: 0.8971516542136677
Iter 64500 | LR: 0.0002923741421438061 | Loss: 0.8920559175312527
Iter 65000 | Perplexity: 32.12309265136719
Iter 65000 | LR: 0.0002922566012974441 | Loss: 0.8970947089791298
Iter 65500 | LR: 0.00029213818824858556 | Loss: 0.9029837238043542
Iter 66000 | LR: 0.00029201890380882044 | Loss: 0.8987710399925705
Iter 66500 | LR: 0.0002918987487957108 | Loss: 0.9007164330780497
Iter 67000 | LR: 0.00029177772403278567 | Loss: 0.8911980465054512
Iter 67500 | LR: 0.00029165583034953537 | Loss: 0.8856994190812111
Iter 68000 | LR: 0.00029153306858140533 | Loss: 0.890739184692502
Iter 68500 | LR: 0.0002914094395697911 | Loss: 0.8905188991129392
Iter 69000 | LR: 0.0002912849441620321 | Loss: 0.8896108889579772
Iter 69500 | LR: 0.0002911595832114058 | Loss: 0.8856576513499023
Iter 70000 | Perplexity: 30.752389907836914
Iter 70000 | LR: 0.0002910333575771222 | Loss: 0.8881612193584442
Iter 70500 | LR: 0.0002909062681243177 | Loss: 0.8882089030742643
Iter 71000 | LR: 0.00029077831572404906 | Loss: 0.8791327406466006
Iter 71500 | LR: 0.0002906495012532879 | Loss: 0.8855141130089755
Iter 72000 | LR: 0.00029051982559491393 | Loss: 0.8769464292377229
Iter 72500 | LR: 0.00029038928963770976 | Loss: 0.8782483177632092
Iter 73000 | LR: 0.0002902578942763542 | Loss: 0.8787502165138726
Iter 73500 | LR: 0.00029012564041141624 | Loss: 0.8775429265201098
Iter 74000 | LR: 0.00028999252894934926 | Loss: 0.8763443313539017
Iter 74500 | LR: 0.0002898585608024842 | Loss: 0.8675659549981354
Iter 75000 | Perplexity: 29.606792449951172
Iter 75000 | LR: 0.0002897237368890237 | Loss: 0.8753591115772725
Iter 75500 | LR: 0.0002895880581330358 | Loss: 0.8803746588528162
Iter 76000 | LR: 0.00028945152546444754 | Loss: 0.8760197370499373
Iter 76500 | LR: 0.00028931413981903855 | Loss: 0.8699728421866894
Iter 77000 | LR: 0.00028917590213843456 | Loss: 0.873238626644015
Iter 77500 | LR: 0.00028903681337010125 | Loss: 0.8771586457639932
Iter 78000 | LR: 0.00028889687446733743 | Loss: 0.8697504835575821
Iter 78500 | LR: 0.00028875608638926866 | Loss: 0.8733766908943651
Iter 79000 | LR: 0.00028861445010084074 | Loss: 0.8722223614156248
Iter 79500 | LR: 0.00028847196657281283 | Loss: 0.871927325949073
Iter 80000 | Perplexity: 28.741907119750977
Iter 80000 | LR: 0.0002883286367817511 | Loss: 0.8747572213411325
Iter 80500 | LR: 0.0002881844617100219 | Loss: 0.8657246044278148
Epoch 3.0
Iter 81000 | LR: 0.0002880394423457851 | Loss: 0.8486514643579732
Iter 81500 | LR: 0.0002878935796829871 | Loss: 0.8381936428695919
Iter 82000 | LR: 0.00028774687472135423 | Loss: 0.8322800977528103
Iter 82500 | LR: 0.00028759932846638596 | Loss: 0.8316572856158018
Iter 83000 | LR: 0.00028745094192934775 | Loss: 0.8318243431299922
Iter 83500 | LR: 0.0002873017161272643 | Loss: 0.8411202029138803
Iter 84000 | LR: 0.0002871516520829126 | Loss: 0.8365351036190984
Iter 84500 | LR: 0.00028700075082481474 | Loss: 0.8316781722009184
Iter 85000 | Perplexity: 28.43962860107422
Iter 85000 | LR: 0.0002868490133872312 | Loss: 0.8356606602668761
Iter 85500 | LR: 0.0002866964408101531 | Loss: 0.8399028414487842
Iter 86000 | LR: 0.0002865430341392961 | Loss: 0.8324738115072254
Iter 86500 | LR: 0.0002863887944260922 | Loss: 0.8377005074173213
Iter 87000 | LR: 0.0002862337227276831 | Loss: 0.8343052014708509
Iter 87500 | LR: 0.0002860778201069129 | Loss: 0.8289562870562077
Iter 88000 | LR: 0.00028592108763232074 | Loss: 0.831919805929065
Iter 88500 | LR: 0.0002857635263781334 | Loss: 0.8328716044127942
Iter 89000 | LR: 0.00028560513742425804 | Loss: 0.8279745838791124
Iter 89500 | LR: 0.0002854459218562749 | Loss: 0.8288832431286567
Iter 90000 | Perplexity: 27.360624313354492
Iter 90000 | LR: 0.00028528588076542964 | Loss: 0.8309858016669742
Iter 90500 | LR: 0.00028512501524862593 | Loss: 0.8270294640213254
Iter 91000 | LR: 0.0002849633264084181 | Loss: 0.8318613577634093
Iter 91500 | LR: 0.00028480081535300325 | Loss: 0.8315474108606579
Iter 92000 | LR: 0.00028463748319621396 | Loss: 0.8344578512758015
Iter 92500 | LR: 0.00028447333105751065 | Loss: 0.8334972316026689
Iter 93000 | LR: 0.0002843083600619736 | Loss: 0.8295227945595975
Iter 93500 | LR: 0.0002841425713402956 | Loss: 0.8390932125598195
Iter 94000 | LR: 0.0002839759660287739 | Loss: 0.8320129627734424
Iter 94500 | LR: 0.00028380854526930283 | Loss: 0.8372233378887166
Iter 95000 | Perplexity: 26.589874267578125
Iter 95000 | LR: 0.0002836403102093653 | Loss: 0.8320917268842463
Iter 95500 | LR: 0.00028347126200202574 | Loss: 0.8301574024558066
Iter 96000 | LR: 0.00028330140180592156 | Loss: 0.8290634820610284
Iter 96500 | LR: 0.00028313073078525553 | Loss: 0.8276409637928006
Iter 97000 | LR: 0.0002829592501097878 | Loss: 0.8292902259528635
Iter 97500 | LR: 0.0002827869609548276 | Loss: 0.8373271318525068
Iter 98000 | LR: 0.00028261386450122557 | Loss: 0.8249823326617481
Iter 98500 | LR: 0.00028243996193536534 | Loss: 0.8277648472040893
Iter 99000 | LR: 0.0002822652544491558 | Loss: 0.8288719586282967
Iter 99500 | LR: 0.00028208974324002233 | Loss: 0.8312094477564093
Iter 100000 | Perplexity: 26.252275466918945
Iter 100000 | LR: 0.00028191342951089924 | Loss: 0.831496540904045
Iter 100500 | LR: 0.0002817363144702209 | Loss: 0.8169846437126393
Iter 101000 | LR: 0.00028155839933191416 | Loss: 0.822898230478167
Iter 101500 | LR: 0.00028137968531538935 | Loss: 0.8194608097523454
Iter 102000 | LR: 0.00028120017364553237 | Loss: 0.8267899144440899
Iter 102500 | LR: 0.0002810198655526961 | Loss: 0.8213885912299158
Iter 103000 | LR: 0.000280838762272692 | Loss: 0.8201665075868361
Iter 103500 | LR: 0.0002806568650467817 | Loss: 0.8244963487237692
Iter 104000 | LR: 0.00028047417512166837 | Loss: 0.8253339314460753
Iter 104500 | LR: 0.0002802906937494884 | Loss: 0.8176212272793049
Iter 105000 | Perplexity: 26.09367561340332
Iter 105000 | LR: 0.0002801064221878024 | Loss: 0.8303762217611077
Iter 105500 | LR: 0.0002799213616995872 | Loss: 0.8257245235890153
Iter 106000 | LR: 0.0002797355135532266 | Loss: 0.8241741374880078
Iter 106500 | LR: 0.00027954887902250297 | Loss: 0.8160983904451132
Iter 107000 | LR: 0.0002793614593865885 | Loss: 0.8214792352169753
Epoch 4.0
Iter 107500 | LR: 0.0002791732559300364 | Loss: 0.8246928475797175
Iter 108000 | LR: 0.000278984269942772 | Loss: 0.7851340091973543
Iter 108500 | LR: 0.0002787945027200842 | Loss: 0.7760407484322792
Iter 109000 | LR: 0.00027860395556261633 | Loss: 0.7838759362697604
Iter 109500 | LR: 0.0002784126297763571 | Loss: 0.7779261897504324
Iter 110000 | Perplexity: 25.623722076416016
Iter 110000 | LR: 0.00027822052667263224 | Loss: 0.7764874815940859
Iter 110500 | LR: 0.0002780276475680947 | Loss: 0.7874636127799749
Iter 111000 | LR: 0.0002778339937847165 | Loss: 0.7817330958694221
Iter 111500 | LR: 0.00027763956664977874 | Loss: 0.7858072635531426
Iter 112000 | LR: 0.0002774443674958634 | Loss: 0.7853626300394532
Iter 112500 | LR: 0.0002772483976608436 | Loss: 0.7836930639296765
Iter 113000 | LR: 0.0002770516584878746 | Loss: 0.7943018280714754
Iter 113500 | LR: 0.00027685415132538467 | Loss: 0.7877923341095437
Iter 114000 | LR: 0.0002766558775270658 | Loss: 0.7879966149479148
Iter 114500 | LR: 0.0002764568384518644 | Loss: 0.7840133482962848
Iter 115000 | Perplexity: 25.410076141357422
Iter 115000 | LR: 0.00027625703546397206 | Loss: 0.7840267404913901
Iter 115500 | LR: 0.0002760564699328161 | Loss: 0.7844067260622971
Iter 116000 | LR: 0.00027585514323305 | Loss: 0.791745798140764
Iter 116500 | LR: 0.0002756530567445447 | Loss: 0.7929781281203033
Iter 117000 | LR: 0.00027545021185237814 | Loss: 0.7894969871640213
Iter 117500 | LR: 0.00027524660994682665 | Loss: 0.791196235269308
Iter 118000 | LR: 0.00027504225242335476 | Loss: 0.7910443630814558
Iter 118500 | LR: 0.00027483714068260624 | Loss: 0.7874090942740445
Iter 119000 | LR: 0.00027463127613039384 | Loss: 0.7793195492029191
Iter 119500 | LR: 0.0002744246601776902 | Loss: 0.7860496208071698
Iter 120000 | Perplexity: 25.109203338623047
Iter 120000 | LR: 0.00027421729424061787 | Loss: 0.7880871019512419
Iter 120500 | LR: 0.00027400917974043984 | Loss: 0.7833945447206503
Iter 121000 | LR: 0.0002738003181035496 | Loss: 0.7906368980556729
Iter 121500 | LR: 0.00027359071076146134 | Loss: 0.7877742870151996
Iter 122000 | LR: 0.00027338035915080045 | Loss: 0.7890585303306585
Iter 122500 | LR: 0.00027316926471329314 | Loss: 0.7874960489571093
Iter 123000 | LR: 0.00027295742889575723 | Loss: 0.7913971627503634
Iter 123500 | LR: 0.00027274485315009154 | Loss: 0.7935090791434052
Iter 124000 | LR: 0.00027253153893326646 | Loss: 0.7827463532239193
Iter 124500 | LR: 0.0002723174877073138 | Loss: 0.7838639464229348
Iter 125000 | Perplexity: 24.700395584106445
Iter 125000 | LR: 0.0002721027009393167 | Loss: 0.7940971583873035
Iter 125500 | LR: 0.00027188718010139957 | Loss: 0.7826436158269641
Iter 126000 | LR: 0.0002716709266707182 | Loss: 0.7796718453615907
Iter 126500 | LR: 0.0002714539421294492 | Loss: 0.7822571212053296
Iter 127000 | LR: 0.0002712362279647805 | Loss: 0.7894179446250205
Iter 127500 | LR: 0.0002710177856689005 | Loss: 0.7846778179705136
Iter 128000 | LR: 0.0002707986167389883 | Loss: 0.7803743460774428
Iter 128500 | LR: 0.00027057872267720323 | Loss: 0.790654384642839
Iter 129000 | LR: 0.00027035810499067447 | Loss: 0.7769951455295084
Iter 129500 | LR: 0.00027013676519149104 | Loss: 0.7852018888294694
Iter 130000 | Perplexity: 24.33718490600586
Iter 130000 | LR: 0.000269914704796691 | Loss: 0.7858636355400087
Iter 130500 | LR: 0.0002696919253282516 | Loss: 0.7889791443198918
Iter 131000 | LR: 0.0002694684283130783 | Loss: 0.7920195614546546
Iter 131500 | LR: 0.0002692442152829946 | Loss: 0.7964218199253076
Iter 132000 | LR: 0.0002690192877747315 | Loss: 0.7817986958473919
Iter 132500 | LR: 0.000268793647329917 | Loss: 0.7839269709587101
Iter 133000 | LR: 0.0002685672954950654 | Loss: 0.7883340957015746
Iter 133500 | LR: 0.00026834023382156687 | Loss: 0.7817353165149685
Iter 134000 | LR: 0.0002681124638656767 | Loss: 0.790536834448576
Epoch 5.0
Iter 134500 | LR: 0.00026788398718850456 | Loss: 0.7795084691047667
Iter 135000 | Perplexity: 24.51234245300293
Iter 135000 | LR: 0.00026765480535600414 | Loss: 0.7414249090850359
Iter 135500 | LR: 0.000267424919938962 | Loss: 0.7362194431573152
Iter 136000 | LR: 0.0002671943325129871 | Loss: 0.7436394509673123
Iter 136500 | LR: 0.00026696304465849977 | Loss: 0.7396475338935851
Iter 137000 | LR: 0.0002667310579607211 | Loss: 0.7462476550787687
Iter 137500 | LR: 0.0002664983740096619 | Loss: 0.7383182437717916
Iter 138000 | LR: 0.000266264994400112 | Loss: 0.7460952769219884
Iter 138500 | LR: 0.00026603092073162907 | Loss: 0.7501761847734459
Iter 139000 | LR: 0.0002657961546085278 | Loss: 0.7471916682273146
Iter 139500 | LR: 0.0002655606976398689 | Loss: 0.7383822533488277
Iter 140000 | Perplexity: 24.602819442749023
Iter 140000 | LR: 0.0002653245514394482 | Loss: 0.7528883676975966
Iter 140500 | LR: 0.0002650877176257852 | Loss: 0.7392608161270621
Iter 141000 | LR: 0.0002648501978221123 | Loss: 0.7467547264695167
Iter 141500 | LR: 0.0002646119936563637 | Loss: 0.747061318680644
Iter 142000 | LR: 0.00026437310676116413 | Loss: 0.7451999115943914
Iter 142500 | LR: 0.0002641335387738175 | Loss: 0.741831819638609
Iter 143000 | LR: 0.0002638932913362961 | Loss: 0.7496076681464915
Iter 143500 | LR: 0.0002636523660952289 | Loss: 0.7546422172337767
Iter 144000 | LR: 0.0002634107647018905 | Loss: 0.7416990929841992
Iter 144500 | LR: 0.0002631684888121899 | Loss: 0.7548162324726594
Iter 145000 | Perplexity: 24.345367431640625
Iter 145000 | LR: 0.0002629255400866588 | Loss: 0.7550125034898518
Iter 145500 | LR: 0.0002626819201904406 | Loss: 0.751528565436602
Iter 146000 | LR: 0.00026243763079327885 | Loss: 0.7504065936058759
Iter 146500 | LR: 0.0002621926735695057 | Loss: 0.7517278394103051
Iter 147000 | LR: 0.00026194705019803047 | Loss: 0.7569742486625911
Iter 147500 | LR: 0.00026170076236232834 | Loss: 0.7562376350909474
Iter 148000 | LR: 0.0002614538117504284 | Loss: 0.7489063528180112
Iter 148500 | LR: 0.0002612062000549027 | Loss: 0.7608709505200393
Iter 149000 | LR: 0.00026095792897285397 | Loss: 0.7617864672094586
Iter 149500 | LR: 0.0002607090002059044 | Loss: 0.7580753130465746
Iter 150000 | Perplexity: 24.423002243041992
Iter 150000 | LR: 0.0002604594154601839 | Loss: 0.7549013081192968
Iter 150500 | LR: 0.00026020917644631835 | Loss: 0.7592335979640489
Iter 151000 | LR: 0.000259958284879418 | Loss: 0.7521066022664313
Iter 151500 | LR: 0.0002597067424790655 | Loss: 0.7562597113847735
Iter 152000 | LR: 0.0002594545509693043 | Loss: 0.7549921451509
Iter 152500 | LR: 0.0002592017120786268 | Loss: 0.7599157601594935
Iter 153000 | LR: 0.0002589482275399624 | Loss: 0.7573044464737175
Iter 153500 | LR: 0.0002586940990906658 | Loss: 0.7505832187086349
Iter 154000 | LR: 0.0002584393284725049 | Loss: 0.7515248496830462
Iter 154500 | LR: 0.000258183917431649 | Loss: 0.7582130553573374
Iter 155000 | Perplexity: 23.86058235168457
Iter 155000 | LR: 0.0002579278677186567 | Loss: 0.7527256340533496
Iter 155500 | LR: 0.00025767118108846427 | Loss: 0.7584804300963885
Iter 156000 | LR: 0.00025741385930037295 | Loss: 0.7603659189492464
Iter 156500 | LR: 0.0002571559041180375 | Loss: 0.7485520654171703
Iter 157000 | LR: 0.0002568973173094539 | Loss: 0.7564999692142008
Iter 157500 | LR: 0.0002566381006469471 | Loss: 0.7583716868609194
Iter 158000 | LR: 0.00025637825590715916 | Loss: 0.7491256149113172
Iter 158500 | LR: 0.00025611778487103686 | Loss: 0.7590156937390563
Iter 159000 | LR: 0.0002558566893238194 | Loss: 0.756966198980808
Iter 159500 | LR: 0.0002555949710550265 | Loss: 0.7576221550256009
Iter 160000 | Perplexity: 23.56981086730957
Iter 160000 | LR: 0.0002553326318584458 | Loss: 0.7559287177026275
Iter 160500 | LR: 0.00025506967353212094 | Loss: 0.7519695852696894
Iter 161000 | LR: 0.0002548060978783387 | Loss: 0.7515017294883729
Epoch 6.0
Iter 161500 | LR: 0.0002545419067036171 | Loss: 0.7355183604359632
Iter 162000 | LR: 0.000254277101818693 | Loss: 0.7036245743930338
Iter 162500 | LR: 0.00025401168503850927 | Loss: 0.7055232452601199
Iter 163000 | LR: 0.0002537456581822029 | Loss: 0.7040075887739659
Iter 163500 | LR: 0.00025347902307309213 | Loss: 0.7061313017457724
Iter 164000 | LR: 0.00025321178153866423 | Loss: 0.7145341441780327
Iter 164500 | LR: 0.0002529439354105626 | Loss: 0.7131213970482344
Iter 165000 | Perplexity: 24.382869720458984
Iter 165000 | LR: 0.00025267548652457475 | Loss: 0.7155517940223226
Iter 165500 | LR: 0.00025240643672061924 | Loss: 0.7092178308963777
Iter 166000 | LR: 0.0002521367878427333 | Loss: 0.7088235694915056
Iter 166500 | LR: 0.00025186654173906014 | Loss: 0.7120964096486566
Iter 167000 | LR: 0.0002515957002618363 | Loss: 0.7105854585766791
Iter 167500 | LR: 0.0002513242652673789 | Loss: 0.7194380722194904
Iter 168000 | LR: 0.00025105223861607306 | Loss: 0.716522451937199
Iter 168500 | LR: 0.000250779622172359 | Loss: 0.7178876224160197
Iter 169000 | LR: 0.0002505064178047192 | Loss: 0.7153357771039008
Iter 169500 | LR: 0.00025023262738566596 | Loss: 0.7161620437353844
Iter 170000 | Perplexity: 24.403671264648438
Iter 170000 | LR: 0.00024995825279172803 | Loss: 0.7176307739317415
Iter 170500 | LR: 0.0002496832959034382 | Loss: 0.7191153029352433
Iter 171000 | LR: 0.0002494077586053202 | Loss: 0.724231590032578
Iter 171500 | LR: 0.0002491316427858758 | Loss: 0.726341786757111
Iter 172000 | LR: 0.00024885495033757183 | Loss: 0.7279986937344073
Iter 172500 | LR: 0.0002485776831568276 | Loss: 0.7283762709796432
Iter 173000 | LR: 0.00024829984314400107 | Loss: 0.7144733450561762
Iter 173500 | LR: 0.0002480214322033767 | Loss: 0.7155114877969024
Iter 174000 | LR: 0.0002477424522431518 | Loss: 0.7173288874328138
Iter 174500 | LR: 0.0002474629051754239 | Loss: 0.7197501598298548
Iter 175000 | Perplexity: 24.098718643188477
Iter 175000 | LR: 0.00024718279291617725 | Loss: 0.7272948597371577
Iter 175500 | LR: 0.0002469021173852699 | Loss: 0.7234055513143534
Iter 176000 | LR: 0.0002466208805064206 | Loss: 0.7241674616187813
Iter 176500 | LR: 0.00024633908420719524 | Loss: 0.7260856352746482
Iter 177000 | LR: 0.0002460567304189943 | Loss: 0.723017680570483
Iter 177500 | LR: 0.00024577382107703895 | Loss: 0.7267644322663536
Iter 178000 | LR: 0.0002454903581203581 | Loss: 0.7186905670166018
Iter 178500 | LR: 0.00024520634349177515 | Loss: 0.7269156832247976
Iter 179000 | LR: 0.0002449217791378946 | Loss: 0.7271118763089182
Iter 179500 | LR: 0.00024463666700908865 | Loss: 0.7246420065313579
Iter 180000 | Perplexity: 23.443058013916016
Iter 180000 | LR: 0.00024435100905948387 | Loss: 0.7234312514960767
Iter 180500 | LR: 0.00024406480724694783 | Loss: 0.7264541427046058
Iter 181000 | LR: 0.0002437780635330758 | Loss: 0.7387752629816532
Iter 181500 | LR: 0.0002434907798831771 | Loss: 0.7243928398936994
Iter 182000 | LR: 0.0002432029582662616 | Loss: 0.7223356427252298
Iter 182500 | LR: 0.0002429146006550265 | Loss: 0.7264503230154513
Iter 183000 | LR: 0.00024262570902584257 | Loss: 0.7325852349400517
Iter 183500 | LR: 0.00024233628535874068 | Loss: 0.7294897191971543
Iter 184000 | LR: 0.00024204633163739828 | Loss: 0.7180134562402963
Iter 184500 | LR: 0.0002417558498491256 | Loss: 0.7273803084343674
Iter 185000 | Perplexity: 23.587648391723633
Iter 185000 | LR: 0.00024146484198485238 | Loss: 0.7326166392862801
Iter 185500 | LR: 0.00024117331003911397 | Loss: 0.7327998536825185
Iter 186000 | LR: 0.00024088125601003758 | Loss: 0.7259640885889536
Iter 186500 | LR: 0.0002405886818993289 | Loss: 0.728781406357884
Iter 187000 | LR: 0.00024029558971225815 | Loss: 0.729668548181653
Iter 187500 | LR: 0.00024000198145764624 | Loss: 0.7326680544763806
Iter 188000 | LR: 0.00023970785914785141 | Loss: 0.7285508695244789
Epoch 7.0
Iter 188500 | LR: 0.00023941322479875498 | Loss: 0.6889869734644898
Iter 189000 | LR: 0.00023911808042974774 | Loss: 0.6820519588887693
Iter 189500 | LR: 0.00023882242806371625 | Loss: 0.6707434459775692
Iter 190000 | Perplexity: 24.26632308959961
Iter 190000 | LR: 0.00023852626972702863 | Loss: 0.6736755669116968
Iter 190500 | LR: 0.00023822960744952098 | Loss: 0.6804726333171123
Iter 191000 | LR: 0.0002379324432644834 | Loss: 0.6793303094804287
Iter 191500 | LR: 0.00023763477920864584 | Loss: 0.6759732870012525
Iter 192000 | LR: 0.0002373366173221645 | Loss: 0.6823119141906505
Iter 192500 | LR: 0.00023703795964860751 | Loss: 0.6789890590310101
Iter 193000 | LR: 0.00023673880823494114 | Loss: 0.6802987948805096
Iter 193500 | LR: 0.00023643916513151568 | Loss: 0.6824620424956082
Iter 194000 | LR: 0.00023613903239205145 | Loss: 0.6822080091387032
Iter 194500 | LR: 0.00023583841207362456 | Loss: 0.6846620588004582
Iter 195000 | Perplexity: 24.52975845336914
Iter 195000 | LR: 0.00023553730623665305 | Loss: 0.6854198957979679
Iter 195500 | LR: 0.00023523571694488265 | Loss: 0.692239034771919
Iter 196000 | LR: 0.00023493364626537254 | Loss: 0.6860543014109126
Iter 196500 | LR: 0.00023463109626848137 | Loss: 0.6946149881184096
Iter 197000 | LR: 0.00023432806902785292 | Loss: 0.6916844106465578
Iter 197500 | LR: 0.00023402456662040196 | Loss: 0.6920088285207748
Iter 198000 | LR: 0.0002337205911263001 | Loss: 0.6824786950647831
Iter 198500 | LR: 0.00023341614462896122 | Loss: 0.6956537721306092
Iter 199000 | LR: 0.00023311122921502753 | Loss: 0.6886602142453192
Iter 199500 | LR: 0.00023280584697435525 | Loss: 0.6873095623403791
Iter 200000 | Perplexity: 24.197832107543945
Iter 200000 | LR: 0.00023249999999999996 | Loss: 0.6918806463480008
Iter 200500 | LR: 0.0002321936903882026 | Loss: 0.6924740742146969
Iter 201000 | LR: 0.000231886920238375 | Loss: 0.6957899970561259
Iter 201500 | LR: 0.00023157969165308532 | Loss: 0.6950432353466751
Iter 202000 | LR: 0.00023127200673804396 | Loss: 0.7026900276541705
Iter 202500 | LR: 0.0002309638676020889 | Loss: 0.7024352245032778
Iter 203000 | LR: 0.00023065527635717116 | Loss: 0.6960455579310658
Iter 203500 | LR: 0.0002303462351183407 | Loss: 0.7008920454233886
Iter 204000 | LR: 0.0002300367460037315 | Loss: 0.6971925786882641
Iter 204500 | LR: 0.00022972681113454734 | Loss: 0.6956257767975336
Iter 205000 | Perplexity: 24.143260955810547
Iter 205000 | LR: 0.0002294164326350471 | Loss: 0.6924069012701517
Iter 205500 | LR: 0.00022910561263253022 | Loss: 0.6992160938680175
Iter 206000 | LR: 0.00022879435325732226 | Loss: 0.6927503322809935
Iter 206500 | LR: 0.00022848265664276006 | Loss: 0.7011786413192755
Iter 207000 | LR: 0.0002281705249251774 | Loss: 0.7011311940848823
Iter 207500 | LR: 0.00022785796024389 | Loss: 0.6972674819082022
Iter 208000 | LR: 0.0002275449647411813 | Loss: 0.7046969731152061
Iter 208500 | LR: 0.0002272315405622874 | Loss: 0.6979254387319084
Iter 209000 | LR: 0.00022691768985538252 | Loss: 0.7038620223104955
Iter 209500 | LR: 0.0002266034147715642 | Loss: 0.6987601793557408
Iter 210000 | Perplexity: 23.701658248901367
Iter 210000 | LR: 0.00022628871746483876 | Loss: 0.7108122545480726
Iter 210500 | LR: 0.00022597360009210632 | Loss: 0.7051896978914741
Iter 211000 | LR: 0.00022565806481314598 | Loss: 0.6990426371246578
Iter 211500 | LR: 0.00022534211379060133 | Loss: 0.6998376036435374
Iter 212000 | LR: 0.00022502574918996517 | Loss: 0.7014804951101534
Iter 212500 | LR: 0.00022470897317956515 | Loss: 0.703932843282818
Iter 213000 | LR: 0.0002243917879305485 | Loss: 0.7021745184808967
Iter 213500 | LR: 0.00022407419561686748 | Loss: 0.7072001006454226
Iter 214000 | LR: 0.0002237561984152642 | Loss: 0.7013134402036665
Iter 214500 | LR: 0.0002234377985052559 | Loss: 0.6976795977354049
Epoch 8.0
Iter 215000 | Perplexity: 23.72165870666504
Iter 215000 | LR: 0.00022311899806911982 | Loss: 0.7051319427788262
Iter 215500 | LR: 0.00022279979929187857 | Loss: 0.6478599306941031
Iter 216000 | LR: 0.00022248020436128478 | Loss: 0.6479206456989047
Iter 216500 | LR: 0.0002221602154678063 | Loss: 0.6415776725858452
Iter 217000 | LR: 0.00022183983480461125 | Loss: 0.6419439673423768
Iter 217500 | LR: 0.00022151906456755277 | Loss: 0.6491952314972885
Iter 218000 | LR: 0.00022119790695515414 | Loss: 0.6495387469977143
Iter 218500 | LR: 0.00022087636416859367 | Loss: 0.6461406859755519
Iter 219000 | LR: 0.00022055443841168966 | Loss: 0.6578489568829536
Iter 219500 | LR: 0.00022023213189088515 | Loss: 0.6467757254838945
Iter 220000 | Perplexity: 25.05775260925293
Iter 220000 | LR: 0.00021990944681523302 | Loss: 0.6529820784181355
Iter 220500 | LR: 0.00021958638539638055 | Loss: 0.6571991635859012
Iter 221000 | LR: 0.0002192629498485546 | Loss: 0.6573782349377869
Iter 221500 | LR: 0.00021893914238854616 | Loss: 0.659199698716402
Iter 222000 | LR: 0.00021861496523569533 | Loss: 0.6581072450429206
Iter 222500 | LR: 0.00021829042061187603 | Loss: 0.6602271784096959
Iter 223000 | LR: 0.00021796551074148074 | Loss: 0.6624737461656327
Iter 223500 | LR: 0.00021764023785140538 | Loss: 0.6639604049921035
Iter 224000 | LR: 0.00021731460417103387 | Loss: 0.6614737121760845
Iter 224500 | LR: 0.000216988611932223 | Loss: 0.6653475279361009
Iter 225000 | Perplexity: 24.715547561645508
Iter 225000 | LR: 0.00021666226336928708 | Loss: 0.6678034423291684
Iter 225500 | LR: 0.00021633556071898262 | Loss: 0.6711064042896032
Iter 226000 | LR: 0.00021600850622049305 | Loss: 0.6652429807931178
Iter 226500 | LR: 0.0002156811021154132 | Loss: 0.6695986769348382
Iter 227000 | LR: 0.00021535335064773418 | Loss: 0.662681378796696
Iter 227500 | LR: 0.00021502525406382787 | Loss: 0.6653969185799355
Iter 228000 | LR: 0.00021469681461243153 | Loss: 0.6679228204488756
Iter 228500 | LR: 0.00021436803454463228 | Loss: 0.6647193670272822
Iter 229000 | LR: 0.00021403891611385207 | Loss: 0.6661231117695565
Iter 229500 | LR: 0.0002137094615758316 | Loss: 0.6716949027776714
Iter 230000 | Perplexity: 24.721771240234375
Iter 230000 | LR: 0.00021337967318861548 | Loss: 0.6711962980777028
Iter 230500 | LR: 0.00021304955321253642 | Loss: 0.6718907881528136
Iter 231000 | LR: 0.0002127191039101997 | Loss: 0.6696567326784129
Iter 231500 | LR: 0.00021238832754646785 | Loss: 0.6675261635333302
Iter 232000 | LR: 0.00021205722638844502 | Loss: 0.6753503900766373
Iter 232500 | LR: 0.00021172580270546152 | Loss: 0.6705400237441066
Iter 233000 | LR: 0.00021139405876905817 | Loss: 0.6787419553846126
Iter 233500 | LR: 0.00021106199685297068 | Loss: 0.6683934105932708
Iter 234000 | LR: 0.00021072961923311432 | Loss: 0.6702349795401107
Iter 234500 | LR: 0.00021039692818756805 | Loss: 0.6783226086944332
Iter 235000 | Perplexity: 24.9240665435791
Iter 235000 | LR: 0.00021006392599655902 | Loss: 0.6701392456889156
Iter 235500 | LR: 0.00020973061494244702 | Loss: 0.6690307815372944
Iter 236000 | LR: 0.0002093969973097087 | Loss: 0.6753707554191347
Iter 236500 | LR: 0.0002090630753849219 | Loss: 0.6776437585800883
Iter 237000 | LR: 0.00020872885145675014 | Loss: 0.6743919903039933
Iter 237500 | LR: 0.00020839432781592679 | Loss: 0.6769335719197987
Iter 238000 | LR: 0.0002080595067552394 | Loss: 0.6742903796583423
Iter 238500 | LR: 0.0002077243905695141 | Loss: 0.6758272659033534
Iter 239000 | LR: 0.00020738898155559963 | Loss: 0.6794514920562507
Iter 239500 | LR: 0.00020705328201235188 | Loss: 0.6769024229049684
Iter 240000 | Perplexity: 24.755355834960938
Iter 240000 | LR: 0.00020671729424061788 | Loss: 0.6781657640635964
Iter 240500 | LR: 0.0002063810205432202 | Loss: 0.6808387365937234
Iter 241000 | LR: 0.00020604446322494113 | Loss: 0.6753057191520927
Iter 241500 | LR: 0.00020570762459250688 | Loss: 0.6853884045034653
Epoch 9.0
Iter 242000 | LR: 0.00020537050695457166 | Loss: 0.656120569631457
Iter 242500 | LR: 0.00020503311262170203 | Loss: 0.6126786419004203
Iter 243000 | LR: 0.000204695443906361 | Loss: 0.6122659196704627
Iter 243500 | LR: 0.00020435750312289213 | Loss: 0.6125793065130707
Iter 244000 | LR: 0.00020401929258750362 | Loss: 0.6179160767048598
Iter 244500 | LR: 0.00020368081461825276 | Loss: 0.6167326135188345
Iter 245000 | Perplexity: 25.888662338256836
Iter 245000 | LR: 0.00020334207153502955 | Loss: 0.6226011341810227
Iter 245500 | LR: 0.00020300306565954114 | Loss: 0.6167254032939675
Iter 246000 | LR: 0.00020266379931529593 | Loss: 0.6275902821123593
Iter 246500 | LR: 0.0002023242748275874 | Loss: 0.6268324533849955
Iter 247000 | LR: 0.00020198449452347837 | Loss: 0.6254646366834633
Iter 247500 | LR: 0.00020164446073178498 | Loss: 0.6306477929651737
Iter 248000 | LR: 0.00020130417578306082 | Loss: 0.6324556101858605
Iter 248500 | LR: 0.00020096364200958083 | Loss: 0.6307339216768747
Iter 249000 | LR: 0.00020062286174532532 | Loss: 0.6300858154147861
Iter 249500 | LR: 0.00020028183732596406 | Loss: 0.6384147385507823
Iter 250000 | Perplexity: 25.783803939819336
Iter 250000 | LR: 0.00019994057108884027 | Loss: 0.6384276986122129
Iter 250500 | LR: 0.0001995990653729545 | Loss: 0.6325898068398234
Iter 251000 | LR: 0.00019925732251894874 | Loss: 0.6396427652239793
Iter 251500 | LR: 0.00019891534486909016 | Loss: 0.6338104603439568
Iter 252000 | LR: 0.0001985731347672554 | Loss: 0.6324817268550398
Iter 252500 | LR: 0.00019823069455891405 | Loss: 0.6438129092007872
Iter 253000 | LR: 0.000197888026591113 | Loss: 0.6393251349776979
Iter 253500 | LR: 0.0001975451332124602 | Loss: 0.637387276440859
Iter 254000 | LR: 0.0001972020167731084 | Loss: 0.6388969636708499
Iter 254500 | LR: 0.00019685867962473925 | Loss: 0.6374253156781199
Iter 255000 | Perplexity: 25.927547454833984
Iter 255000 | LR: 0.00019651512412054723 | Loss: 0.6439967706799508
Iter 255500 | LR: 0.00019617135261522313 | Loss: 0.6433627627789976
Iter 256000 | LR: 0.0001958273674649385 | Loss: 0.6432921924442053
Iter 256500 | LR: 0.00019548317102732898 | Loss: 0.6478618212789302
Iter 257000 | LR: 0.00019513876566147842 | Loss: 0.6446446780115362
Iter 257500 | LR: 0.00019479415372790265 | Loss: 0.6460239829123021
Iter 258000 | LR: 0.00019444933758853324 | Loss: 0.6431529738008971
Iter 258500 | LR: 0.00019410431960670144 | Loss: 0.6479562570899723
Iter 259000 | LR: 0.00019375910214712182 | Loss: 0.643123341947794
Iter 259500 | LR: 0.0001934136875758762 | Loss: 0.6436946810781948
Iter 260000 | Perplexity: 25.6503963470459
Iter 260000 | LR: 0.00019306807826039745 | Loss: 0.6521327904611822
Iter 260500 | LR: 0.00019272227656945312 | Loss: 0.6475436879694472
Iter 261000 | LR: 0.00019237628487312914 | Loss: 0.6435814017057422
Iter 261500 | LR: 0.00019203010554281398 | Loss: 0.6484741787612438
Iter 262000 | LR: 0.000191683740951182 | Loss: 0.6490281456708906
Iter 262500 | LR: 0.0001913371934721773 | Loss: 0.6536459147930146
Iter 263000 | LR: 0.00019099046548099748 | Loss: 0.654528394713998
Iter 263500 | LR: 0.0001906435593540774 | Loss: 0.6389938887208699
Iter 264000 | LR: 0.0001902964774690728 | Loss: 0.654104762002826
Iter 264500 | LR: 0.00018994922220484406 | Loss: 0.6523883998394012
Iter 265000 | Perplexity: 25.172992706298828
Iter 265000 | LR: 0.00018960179594143992 | Loss: 0.652200737074018
Iter 265500 | LR: 0.000189254201060081 | Loss: 0.6540950229018929
Iter 266000 | LR: 0.00018890643994314373 | Loss: 0.6526754840463395
Iter 266500 | LR: 0.0001885585149741439 | Loss: 0.6515339036285881
Iter 267000 | LR: 0.00018821042853772024 | Loss: 0.650916401445866
Iter 267500 | LR: 0.00018786218301961827 | Loss: 0.651647154837847
Iter 268000 | LR: 0.00018751378080667378 | Loss: 0.6544822071492679
Iter 268500 | LR: 0.00018716522428679648 | Loss: 0.6534386833757159
Epoch 10.0
Iter 269000 | LR: 0.00018681651584895374 | Loss: 0.6233036021888255
Iter 269500 | LR: 0.00018646765788315415 | Loss: 0.5917873211950064
Iter 270000 | Perplexity: 26.889328002929688
Iter 270000 | LR: 0.00018611865278043115 | Loss: 0.5898163980990647
Iter 270500 | LR: 0.00018576950293282664 | Loss: 0.5907740110903976
Iter 271000 | LR: 0.0001854202107333746 | Loss: 0.5919417380541564
Iter 271500 | LR: 0.0001850707785760846 | Loss: 0.5897251202166086
Iter 272000 | LR: 0.00018472120885592555 | Loss: 0.5919919926673168
Iter 272500 | LR: 0.00018437150396880916 | Loss: 0.5998948007076974
Iter 273000 | LR: 0.00018402166631157363 | Loss: 0.5990230529010293
Iter 273500 | LR: 0.00018367169828196705 | Loss: 0.5959280052781102
Iter 274000 | LR: 0.00018332160227863106 | Loss: 0.5993664815276856
Iter 274500 | LR: 0.00018297138070108454 | Loss: 0.6013247952610254
Iter 275000 | Perplexity: 27.3205623626709
Iter 275000 | LR: 0.00018262103594970697 | Loss: 0.6035407989472155
Iter 275500 | LR: 0.00018227057042572196 | Loss: 0.6084437023103233
Iter 276000 | LR: 0.00018191998653118105 | Loss: 0.6025896161794665
Iter 276500 | LR: 0.00018156928666894699 | Loss: 0.6071646725386383
Iter 277000 | LR: 0.00018121847324267733 | Loss: 0.607699770480394
Iter 277500 | LR: 0.00018086754865680806 | Loss: 0.6076124148070813
Iter 278000 | LR: 0.00018051651531653698 | Loss: 0.6111073148995642
Iter 278500 | LR: 0.00018016537562780727 | Loss: 0.6136089897155763
Iter 279000 | LR: 0.00017981413199729106 | Loss: 0.6132537215948106
Iter 279500 | LR: 0.0001794627868323729 | Loss: 0.6070233899354932
Iter 280000 | Perplexity: 27.47475814819336
Iter 280000 | LR: 0.0001791113425411332 | Loss: 0.6111845204979178
Iter 280500 | LR: 0.00017875980153233173 | Loss: 0.6146673728525639
Iter 281000 | LR: 0.00017840816621539124 | Loss: 0.6126434969902034
Iter 281500 | LR: 0.0001780564390003808 | Loss: 0.6112452562898404
Iter 282000 | LR: 0.00017770462229799944 | Loss: 0.6107248480618
Iter 282500 | LR: 0.0001773527185195593 | Loss: 0.6080243010073904
Iter 283000 | LR: 0.0001770007300769696 | Loss: 0.6200318491458899
Iter 283500 | LR: 0.00017664865938271966 | Loss: 0.6184633733332152
Iter 284000 | LR: 0.0001762965088498626 | Loss: 0.6178015519678597
Iter 284500 | LR: 0.00017594428089199872 | Loss: 0.6160899178683763
Iter 285000 | Perplexity: 26.895002365112305
Iter 285000 | LR: 0.00017559197792325906 | Loss: 0.6199545967578876
Iter 285500 | LR: 0.00017523960235828865 | Loss: 0.6221060950309046
Iter 286000 | LR: 0.00017488715661223025 | Loss: 0.6209811896830797
Iter 286500 | LR: 0.00017453464310070749 | Loss: 0.6184076058119531
Iter 287000 | LR: 0.00017418206423980848 | Loss: 0.6228177080303425
Iter 287500 | LR: 0.0001738294224460693 | Loss: 0.6281311818212266
Iter 288000 | LR: 0.0001734767201364573 | Loss: 0.6225575383007526
Iter 288500 | LR: 0.00017312395972835458 | Loss: 0.6213047418743376
Iter 289000 | LR: 0.00017277114363954156 | Loss: 0.6233984569460147
Iter 289500 | LR: 0.00017241827428818017 | Loss: 0.6299487008154395
Iter 290000 | Perplexity: 26.383848190307617
Iter 290000 | LR: 0.0001720653540927974 | Loss: 0.6188957852870223
Iter 290500 | LR: 0.0001717123854722688 | Loss: 0.6267034155875447
Iter 291000 | LR: 0.0001713593708458017 | Loss: 0.6217265251278876
Iter 291500 | LR: 0.00017100631263291895 | Loss: 0.6220619099587208
Iter 292000 | LR: 0.00017065321325344192 | Loss: 0.6267592807114133
Iter 292500 | LR: 0.00017030007512747425 | Loss: 0.6306579414755095
Iter 293000 | LR: 0.00016994690067538508 | Loss: 0.6276771635562186
Iter 293500 | LR: 0.00016959369231779256 | Loss: 0.6302848269045347
Iter 294000 | LR: 0.0001692404524755473 | Loss: 0.6339506121724844
Iter 294500 | LR: 0.00016888718356971552 | Loss: 0.6298773730546234
Iter 295000 | Perplexity: 26.435588836669922
Iter 295000 | LR: 0.00016853388802156287 | Loss: 0.6259066496044394
Iter 295500 | LR: 0.00016818056825253737 | Loss: 0.6256181491911409
Epoch 11.0
Iter 296000 | LR: 0.00016782722668425316 | Loss: 0.5705402719974518
Iter 296500 | LR: 0.00016747386573847387 | Loss: 0.5573285943269737
Iter 297000 | LR: 0.00016712048783709576 | Loss: 0.5611940582096573
Iter 297500 | LR: 0.00016676709540213146 | Loss: 0.5601417222619055
Iter 298000 | LR: 0.00016641369085569315 | Loss: 0.564237592667341
Iter 298500 | LR: 0.000166060276619976 | Loss: 0.5645608480274679
Iter 299000 | LR: 0.00016570685511724159 | Loss: 0.5654602357000112
Iter 299500 | LR: 0.00016535342876980143 | Loss: 0.5742972886562355
Iter 300000 | Perplexity: 28.65384292602539
Iter 300000 | LR: 0.00016499999999999997 | Loss: 0.5694867916405201
Iter 300500 | LR: 0.00016464657123019854 | Loss: 0.5733913925290115
Iter 301000 | LR: 0.0001642931448827583 | Loss: 0.5737350329011671
Iter 301500 | LR: 0.000163939723380024 | Loss: 0.5777232072502381
Iter 302000 | LR: 0.00016358630914430682 | Loss: 0.5814751629531382
Iter 302500 | LR: 0.0001632329045978685 | Loss: 0.5767541801184415
Iter 303000 | LR: 0.0001628795121629042 | Loss: 0.5798561727255579
Iter 303500 | LR: 0.0001625261342615261 | Loss: 0.5731782294809817
Iter 304000 | LR: 0.00016217277331574678 | Loss: 0.5796260519325738
Iter 304500 | LR: 0.00016181943174746263 | Loss: 0.5841961071640254
Iter 305000 | Perplexity: 29.058128356933594
Iter 305000 | LR: 0.00016146611197843713 | Loss: 0.586345358416439
Iter 305500 | LR: 0.00016111281643028442 | Loss: 0.5849571982026097
Iter 306000 | LR: 0.00016075954752445265 | Loss: 0.5818498912453651
Iter 306500 | LR: 0.00016040630768220736 | Loss: 0.579831511750817
Iter 307000 | LR: 0.00016005309932461487 | Loss: 0.593381807953119
Iter 307500 | LR: 0.00015969992487252575 | Loss: 0.5873585118353366
Iter 308000 | LR: 0.00015934678674655805 | Loss: 0.5898537324368959
Iter 308500 | LR: 0.00015899368736708102 | Loss: 0.5916176332533359
Iter 309000 | LR: 0.00015864062915419823 | Loss: 0.5865438271313906
Iter 309500 | LR: 0.00015828761452773118 | Loss: 0.5985276796668771
Iter 310000 | Perplexity: 28.76791000366211
Iter 310000 | LR: 0.00015793464590720254 | Loss: 0.5947454988956445
Iter 310500 | LR: 0.00015758172571181983 | Loss: 0.5889461615681647
Iter 311000 | LR: 0.0001572288563604584 | Loss: 0.5954023560136562
Iter 311500 | LR: 0.00015687604027164536 | Loss: 0.5895162065327173
Iter 312000 | LR: 0.00015652327986354268 | Loss: 0.5926152694970369
Iter 312500 | LR: 0.00015617057755393064 | Loss: 0.597728128880263
Iter 313000 | LR: 0.00015581793576019152 | Loss: 0.5962720809876917
Iter 313500 | LR: 0.0001554653568992925 | Loss: 0.6006195209175348
Iter 314000 | LR: 0.00015511284338776973 | Loss: 0.5916586632281544
Iter 314500 | LR: 0.0001547603976417113 | Loss: 0.5955111598968507
Iter 315000 | Perplexity: 28.43613052368164
Iter 315000 | LR: 0.0001544080220767409 | Loss: 0.6034482549875974
Iter 315500 | LR: 0.00015405571910800126 | Loss: 0.5972717325389387
Iter 316000 | LR: 0.0001537034911501374 | Loss: 0.5897547025978565
Iter 316500 | LR: 0.00015335134061728034 | Loss: 0.6015121687203646
Iter 317000 | LR: 0.00015299926992303037 | Loss: 0.5984508612751968
Iter 317500 | LR: 0.00015264728148044066 | Loss: 0.5951846677809957
Iter 318000 | LR: 0.00015229537770200055 | Loss: 0.6072317509353158
Iter 318500 | LR: 0.0001519435609996191 | Loss: 0.5999187318980692
Iter 319000 | LR: 0.00015159183378460876 | Loss: 0.6003556661307806
Iter 319500 | LR: 0.00015124019846766827 | Loss: 0.6052288452535864
Iter 320000 | Perplexity: 28.089191436767578
Iter 320000 | LR: 0.0001508886574588668 | Loss: 0.6070223958790302
Iter 320500 | LR: 0.00015053721316762706 | Loss: 0.6007408583909271
Iter 321000 | LR: 0.00015018586800270888 | Loss: 0.6067757613211874
Iter 321500 | LR: 0.00014983462437219268 | Loss: 0.5955262164026499
Iter 322000 | LR: 0.00014948348468346302 | Loss: 0.5996280822157865
Epoch 12.0
Iter 322500 | LR: 0.00014913245134319191 | Loss: 0.5981519414484497
Iter 323000 | LR: 0.0001487815267573226 | Loss: 0.5360650204867126
Iter 323500 | LR: 0.00014843071333105296 | Loss: 0.5347040039300918
Iter 324000 | LR: 0.0001480800134688189 | Loss: 0.535698578059673
Iter 324500 | LR: 0.00014772942957427799 | Loss: 0.5367799763381483
Iter 325000 | Perplexity: 30.959144592285156
Iter 325000 | LR: 0.00014737896405029306 | Loss: 0.5428189082443715
Iter 325500 | LR: 0.00014702861929891543 | Loss: 0.5407962398976086
Iter 326000 | LR: 0.0001466783977213689 | Loss: 0.5492434926331047
Iter 326500 | LR: 0.00014632830171803292 | Loss: 0.5409805054217578
Iter 327000 | LR: 0.00014597833368842631 | Loss: 0.5388341426104308
Iter 327500 | LR: 0.00014562849603119078 | Loss: 0.549334366172552
Iter 328000 | LR: 0.00014527879114407442 | Loss: 0.54541032359004
Iter 328500 | LR: 0.00014492922142391538 | Loss: 0.5552624820172787
Iter 329000 | LR: 0.00014457978926662538 | Loss: 0.5511400763690475
Iter 329500 | LR: 0.0001442304970671733 | Loss: 0.5472674446552989
Iter 330000 | Perplexity: 30.756223678588867
Iter 330000 | LR: 0.0001438813472195688 | Loss: 0.5536906117945909
Iter 330500 | LR: 0.00014353234211684585 | Loss: 0.550857695043087
Iter 331000 | LR: 0.00014318348415104625 | Loss: 0.5528946627676481
Iter 331500 | LR: 0.0001428347757132035 | Loss: 0.5624215580523013
Iter 332000 | LR: 0.0001424862191933262 | Loss: 0.5500423662364484
Iter 332500 | LR: 0.00014213781698038167 | Loss: 0.5601912423223256
Iter 333000 | LR: 0.00014178957146227967 | Loss: 0.5564464566111568
Iter 333500 | LR: 0.00014144148502585608 | Loss: 0.5578793440014121
Iter 334000 | LR: 0.00014109356005685624 | Loss: 0.5647805806994435
Iter 334500 | LR: 0.00014074579893991898 | Loss: 0.5697245375812057
Iter 335000 | Perplexity: 30.724071502685547
Iter 335000 | LR: 0.00014039820405856008 | Loss: 0.5594397091865534
Iter 335500 | LR: 0.00014005077779515588 | Loss: 0.5659856810420755
Iter 336000 | LR: 0.00013970352253092714 | Loss: 0.5678015936166048
Iter 336500 | LR: 0.00013935644064592257 | Loss: 0.5617974494397642
Iter 337000 | LR: 0.00013900953451900252 | Loss: 0.5590634197741746
Iter 337500 | LR: 0.00013866280652782267 | Loss: 0.5652531050890685
Iter 338000 | LR: 0.00013831625904881794 | Loss: 0.5700560468435286
Iter 338500 | LR: 0.00013796989445718594 | Loss: 0.5668049221485848
Iter 339000 | LR: 0.00013762371512687083 | Loss: 0.5632869993895289
Iter 339500 | LR: 0.0001372777234305469 | Loss: 0.5714680651575323
Iter 340000 | Perplexity: 30.218950271606445
Iter 340000 | LR: 0.0001369319217396025 | Loss: 0.5730354572832584
Iter 340500 | LR: 0.00013658631242412375 | Loss: 0.5661051178723576
Iter 341000 | LR: 0.00013624089785287816 | Loss: 0.5752058593183756
Iter 341500 | LR: 0.00013589568039329856 | Loss: 0.5709941814094782
Iter 342000 | LR: 0.00013555066241146679 | Loss: 0.5696561297029248
Iter 342500 | LR: 0.00013520584627209735 | Loss: 0.5759079284220937
Iter 343000 | LR: 0.00013486123433852158 | Loss: 0.5668824630230664
Iter 343500 | LR: 0.000134516828972671 | Loss: 0.5716097608953723
Iter 344000 | LR: 0.00013417263253506144 | Loss: 0.5716220574826012
Iter 344500 | LR: 0.0001338286473847768 | Loss: 0.5710963509976863
Iter 345000 | Perplexity: 30.191669464111328
Iter 345000 | LR: 0.0001334848758794528 | Loss: 0.576662866100669
Iter 345500 | LR: 0.00013314132037526072 | Loss: 0.5718816802650695
Iter 346000 | LR: 0.0001327979832268916 | Loss: 0.5763901109248407
Iter 346500 | LR: 0.00013245486678753978 | Loss: 0.5768160252273085
Iter 347000 | LR: 0.00013211197340888694 | Loss: 0.5764626036584379
Iter 347500 | LR: 0.00013176930544108592 | Loss: 0.5803266962617638
Iter 348000 | LR: 0.0001314268652327446 | Loss: 0.5784758343547577
Iter 348500 | LR: 0.0001310846551309098 | Loss: 0.576018213555217
Iter 349000 | LR: 0.00013074267748105123 | Loss: 0.5769056407362222
Epoch 13.0
Iter 349500 | LR: 0.00013040093462704543 | Loss: 0.559081346169114
Iter 350000 | Perplexity: 32.34553527832031
Iter 350000 | LR: 0.00013005942891115968 | Loss: 0.5088585960865021
Iter 350500 | LR: 0.00012971816267403594 | Loss: 0.5108265197277074
Iter 351000 | LR: 0.00012937713825467468 | Loss: 0.5118156883865594
Iter 351500 | LR: 0.00012903635799041914 | Loss: 0.5077787762880325
Iter 352000 | LR: 0.00012869582421693912 | Loss: 0.5158432660251858
Iter 352500 | LR: 0.00012835553926821496 | Loss: 0.517730801664293
Iter 353000 | LR: 0.0001280155054765216 | Loss: 0.5137480067461727
Iter 353500 | LR: 0.0001276757251724126 | Loss: 0.5205811448395253
Iter 354000 | LR: 0.00012733620068470405 | Loss: 0.5273390065133569
Iter 354500 | LR: 0.0001269969343404588 | Loss: 0.5159442025423047
Iter 355000 | Perplexity: 33.14889144897461
Iter 355000 | LR: 0.00012665792846497042 | Loss: 0.5221377957612277
Iter 355500 | LR: 0.0001263191853817472 | Loss: 0.523205347806216
Iter 356000 | LR: 0.0001259807074124963 | Loss: 0.5221030724048611
Iter 356500 | LR: 0.0001256424968771079 | Loss: 0.5248608502745626
Iter 357000 | LR: 0.00012530455609363896 | Loss: 0.529183926209807
Iter 357500 | LR: 0.0001249668873782979 | Loss: 0.5340199883282187
Iter 358000 | LR: 0.00012462949304542829 | Loss: 0.534247971922159
Iter 358500 | LR: 0.0001242923754074931 | Loss: 0.5233502058684829
Iter 359000 | LR: 0.00012395553677505878 | Loss: 0.532696486338973
Iter 359500 | LR: 0.00012361897945677977 | Loss: 0.5381811717152595
Iter 360000 | Perplexity: 32.847625732421875
Iter 360000 | LR: 0.0001232827057593821 | Loss: 0.5315663130581376
Iter 360500 | LR: 0.0001229467179876481 | Loss: 0.5261808878928421
Iter 361000 | LR: 0.0001226110184444003 | Loss: 0.5333110570907595
Iter 361500 | LR: 0.00012227560943048587 | Loss: 0.5421546675264839
Iter 362000 | LR: 0.00012194049324476052 | Loss: 0.5346594567596911
Iter 362500 | LR: 0.0001216056721840732 | Loss: 0.5457155480980874
Iter 363000 | LR: 0.00012127114854324983 | Loss: 0.5360719312354922
Iter 363500 | LR: 0.00012093692461507806 | Loss: 0.5343387027829886
Iter 364000 | LR: 0.00012060300269029124 | Loss: 0.5354056615382431
Iter 364500 | LR: 0.00012026938505755288 | Loss: 0.5399860270321369
Iter 365000 | Perplexity: 32.90876007080078
Iter 365000 | LR: 0.00011993607400344092 | Loss: 0.5415587394684549
Iter 365500 | LR: 0.00011960307181243192 | Loss: 0.5399846848100424
Iter 366000 | LR: 0.00011927038076688565 | Loss: 0.5413176760822529
Iter 366500 | LR: 0.00011893800314702927 | Loss: 0.5416080924868596
Iter 367000 | LR: 0.00011860594123094181 | Loss: 0.544470640793443
Iter 367500 | LR: 0.0001182741972945384 | Loss: 0.5414130005985495
Iter 368000 | LR: 0.00011794277361155496 | Loss: 0.5456018233299257
Iter 368500 | LR: 0.00011761167245353214 | Loss: 0.5510074482858178
Iter 369000 | LR: 0.00011728089608980029 | Loss: 0.5492810801416637
Iter 369500 | LR: 0.00011695044678746355 | Loss: 0.5460603499412536
Iter 370000 | Perplexity: 32.34632110595703
Iter 370000 | LR: 0.00011662032681138445 | Loss: 0.5517684262990956
Iter 370500 | LR: 0.00011629053842416833 | Loss: 0.546064186245203
Iter 371000 | LR: 0.00011596108388614792 | Loss: 0.5457391113042838
Iter 371500 | LR: 0.00011563196545536765 | Loss: 0.5509739089012149
Iter 372000 | LR: 0.00011530318538756846 | Loss: 0.5464232760667803
Iter 372500 | LR: 0.00011497474593617208 | Loss: 0.5526461708545684
Iter 373000 | LR: 0.00011464664935226576 | Loss: 0.5491422046720983
Iter 373500 | LR: 0.00011431889788458675 | Loss: 0.5491475884616376
Iter 374000 | LR: 0.00011399149377950693 | Loss: 0.5505070772767071
Iter 374500 | LR: 0.00011366443928101734 | Loss: 0.54819916985929
Iter 375000 | Perplexity: 32.103309631347656
Iter 375000 | LR: 0.00011333773663071286 | Loss: 0.5565153986215591
Iter 375500 | LR: 0.00011301138806777695 | Loss: 0.5539474269002674
Iter 376000 | LR: 0.00011268539582896609 | Loss: 0.5460758761316538
Epoch 14.0
Iter 376500 | LR: 0.0001123597621485946 | Loss: 0.5197765226289625
Iter 377000 | LR: 0.00011203448925851922 | Loss: 0.48746279135346404
Iter 377500 | LR: 0.00011170957938812391 | Loss: 0.4887489868700509
Iter 378000 | LR: 0.00011138503476430461 | Loss: 0.4861119443923233
Iter 378500 | LR: 0.0001110608576114538 | Loss: 0.4915450570732354
Iter 379000 | LR: 0.00011073705015144538 | Loss: 0.4909423039853569
Iter 379500 | LR: 0.00011041361460361942 | Loss: 0.49479241386055933
Iter 380000 | Perplexity: 35.794212341308594
Iter 380000 | LR: 0.00011009055318476698 | Loss: 0.4928989508375523
Iter 380500 | LR: 0.0001097678681091148 | Loss: 0.4943301112204793
Iter 381000 | LR: 0.0001094455615883103 | Loss: 0.4922141498699786
Iter 381500 | LR: 0.00010912363583140629 | Loss: 0.49953062117099756
Iter 382000 | LR: 0.00010880209304484584 | Loss: 0.49806043349206425
Iter 382500 | LR: 0.00010848093543244723 | Loss: 0.5024698963016274
Iter 383000 | LR: 0.00010816016519538871 | Loss: 0.49951053481548985
Iter 383500 | LR: 0.00010783978453219365 | Loss: 0.5046300870925187
Iter 384000 | LR: 0.00010751979563871518 | Loss: 0.5077348648384216
Iter 384500 | LR: 0.0001072002007081214 | Loss: 0.5050079993531106
Iter 385000 | Perplexity: 35.93561935424805
Iter 385000 | LR: 0.0001068810019308801 | Loss: 0.5065535232424738
Iter 385500 | LR: 0.00010656220149474416 | Loss: 0.5058181162923568
Iter 386000 | LR: 0.00010624380158473578 | Loss: 0.5052740906924018
Iter 386500 | LR: 0.0001059258043831325 | Loss: 0.5075327219814063
Iter 387000 | LR: 0.00010560821206945143 | Loss: 0.5070725020766259
Iter 387500 | LR: 0.00010529102682043484 | Loss: 0.5094219519570471
Iter 388000 | LR: 0.00010497425081003481 | Loss: 0.5075552836060524
Iter 388500 | LR: 0.00010465788620939864 | Loss: 0.5097381043434144
Iter 389000 | LR: 0.00010434193518685396 | Loss: 0.5051708926260466
Iter 389500 | LR: 0.00010402639990789362 | Loss: 0.5129894400388004
Iter 390000 | Perplexity: 35.655479431152344
Iter 390000 | LR: 0.00010371128253516117 | Loss: 0.5151765895634888
Iter 390500 | LR: 0.00010339658522843571 | Loss: 0.5093859816342586
Iter 391000 | LR: 0.00010308231014461752 | Loss: 0.5119917055219414
Iter 391500 | LR: 0.00010276845943771258 | Loss: 0.5169539850950239
Iter 392000 | LR: 0.00010245503525881869 | Loss: 0.5164598687738179
Iter 392500 | LR: 0.00010214203975610994 | Loss: 0.5117575120925901
Iter 393000 | LR: 0.0001018294750748226 | Loss: 0.5147529041022064
Iter 393500 | LR: 0.00010151734335723987 | Loss: 0.5175753506273034
Iter 394000 | LR: 0.00010120564674267771 | Loss: 0.5159740747511391
Iter 394500 | LR: 0.00010089438736746974 | Loss: 0.5217354483902452
Iter 395000 | Perplexity: 35.60675048828125
Iter 395000 | LR: 0.00010058356736495284 | Loss: 0.515818512812257
Iter 395500 | LR: 0.00010027318886545261 | Loss: 0.5188901837170125
Iter 396000 | LR: 9.99632539962684e-05 | Loss: 0.5238998198509217
Iter 396500 | LR: 9.965376488165923e-05 | Loss: 0.5238801795989277
Iter 397000 | LR: 9.934472364282877e-05 | Loss: 0.5239097730815411
Iter 397500 | LR: 9.903613239791111e-05 | Loss: 0.5203216328471899
Iter 398000 | LR: 9.872799326195598e-05 | Loss: 0.5168015803396704
Iter 398500 | LR: 9.842030834691465e-05 | Loss: 0.521095852032304
Iter 399000 | LR: 9.811307976162496e-05 | Loss: 0.5211005749553442
Iter 399500 | LR: 9.780630961179735e-05 | Loss: 0.5227817347645759
Iter 400000 | Perplexity: 35.089664459228516
Iter 400000 | LR: 9.750000000000001e-05 | Loss: 0.5211099809408188
Iter 400500 | LR: 9.719415302564469e-05 | Loss: 0.5227713749557729
Iter 401000 | LR: 9.68887707849724e-05 | Loss: 0.5257728251814844
Iter 401500 | LR: 9.658385537103872e-05 | Loss: 0.5295800192654129
Iter 402000 | LR: 9.627940887369986e-05 | Loss: 0.526738601103425
Iter 402500 | LR: 9.597543337959797e-05 | Loss: 0.5266129411011928
Iter 403000 | LR: 9.567193097214706e-05 | Loss: 0.5321533195674425
Epoch 15.0
Iter 403500 | LR: 9.536890373151859e-05 | Loss: 0.4830314833670857
Iter 404000 | LR: 9.506635373462743e-05 | Loss: 0.46723556745797423
Iter 404500 | LR: 9.47642830551173e-05 | Loss: 0.4624258036911486
Iter 405000 | Perplexity: 38.65889358520508
Iter 405000 | LR: 9.446269376334689e-05 | Loss: 0.46064625106751933
Iter 405500 | LR: 9.416158792637543e-05 | Loss: 0.4635778547450903
Iter 406000 | LR: 9.38609676079485e-05 | Loss: 0.46551387414336187
Iter 406500 | LR: 9.356083486848427e-05 | Loss: 0.467504541389644
Iter 407000 | LR: 9.326119176505878e-05 | Loss: 0.46640558056533293
Iter 407500 | LR: 9.296204035139243e-05 | Loss: 0.4711256951466206
Iter 408000 | LR: 9.26633826778354e-05 | Loss: 0.47157987155020215
Iter 408500 | LR: 9.236522079135413e-05 | Loss: 0.4764672213792804
Iter 409000 | LR: 9.206755673551656e-05 | Loss: 0.4705721292272214
Iter 409500 | LR: 9.177039255047898e-05 | Loss: 0.47862868957221516
Iter 410000 | Perplexity: 39.16008758544922
Iter 410000 | LR: 9.147373027297134e-05 | Loss: 0.4775221155956391
Iter 410500 | LR: 9.117757193628373e-05 | Loss: 0.47740220725536353
Iter 411000 | LR: 9.088191957025218e-05 | Loss: 0.4777164363116028
Iter 411500 | LR: 9.058677520124504e-05 | Loss: 0.4826339605450628
Iter 412000 | LR: 9.029214085214854e-05 | Loss: 0.4833797283098102
Iter 412500 | LR: 8.999801854235373e-05 | Loss: 0.48435402542352685
Iter 413000 | LR: 8.970441028774183e-05 | Loss: 0.4869174659252168
Iter 413500 | LR: 8.941131810067101e-05 | Loss: 0.484010393694043
Iter 414000 | LR: 8.91187439899624e-05 | Loss: 0.48464157216250936
Iter 414500 | LR: 8.8826689960886e-05 | Loss: 0.4814331281185151
Iter 415000 | Perplexity: 39.225685119628906
Iter 415000 | LR: 8.853515801514759e-05 | Loss: 0.4817247414588929
Iter 415500 | LR: 8.824415015087435e-05 | Loss: 0.4878054172545675
Iter 416000 | LR: 8.795366836260173e-05 | Loss: 0.48931364476680705
Iter 416500 | LR: 8.766371464125926e-05 | Loss: 0.4890995157510038
Iter 417000 | LR: 8.737429097415743e-05 | Loss: 0.48716998711228404
Iter 417500 | LR: 8.708539934497347e-05 | Loss: 0.49284179721027604
Iter 418000 | LR: 8.679704173373838e-05 | Loss: 0.4894471559301017
Iter 418500 | LR: 8.650922011682286e-05 | Loss: 0.492167205065489
Iter 419000 | LR: 8.622193646692415e-05 | Loss: 0.48919175855815494
Iter 419500 | LR: 8.593519275305211e-05 | Loss: 0.49028173506259864
Iter 420000 | Perplexity: 38.930747985839844
Iter 420000 | LR: 8.564899094051613e-05 | Loss: 0.4878345071151853
Iter 420500 | LR: 8.536333299091135e-05 | Loss: 0.49395440816879266
Iter 421000 | LR: 8.507822086210535e-05 | Loss: 0.489190849363804
Iter 421500 | LR: 8.479365650822479e-05 | Loss: 0.49234391536563643
Iter 422000 | LR: 8.450964187964185e-05 | Loss: 0.49127920974045974
Iter 422500 | LR: 8.422617892296102e-05 | Loss: 0.5021082612872124
Iter 423000 | LR: 8.394326958100566e-05 | Loss: 0.49297835156321573
Iter 423500 | LR: 8.366091579280472e-05 | Loss: 0.4971336484700441
Iter 424000 | LR: 8.33791194935794e-05 | Loss: 0.4968372736871247
Iter 424500 | LR: 8.309788261473006e-05 | Loss: 0.496385727599263
Iter 425000 | Perplexity: 38.78758239746094
Iter 425000 | LR: 8.281720708382271e-05 | Loss: 0.49535559143871094
Iter 425500 | LR: 8.253709482457607e-05 | Loss: 0.4974837995693088
Iter 426000 | LR: 8.225754775684819e-05 | Loss: 0.4978642956912518
Iter 426500 | LR: 8.197856779662331e-05 | Loss: 0.5011402315646412
Iter 427000 | LR: 8.170015685599894e-05 | Loss: 0.4969916521757843
Iter 427500 | LR: 8.142231684317239e-05 | Loss: 0.5016095158830283
Iter 428000 | LR: 8.11450496624281e-05 | Loss: 0.49950957704335486
Iter 428500 | LR: 8.086835721412423e-05 | Loss: 0.5053568252548577
Iter 429000 | LR: 8.059224139467983e-05 | Loss: 0.5039940937235947
Iter 429500 | LR: 8.031670409656178e-05 | Loss: 0.49568143915385005
Epoch 16.0
Iter 430000 | Perplexity: 38.56477355957031
Iter 430000 | LR: 8.004174720827196e-05 | Loss: 0.5016840642690656
Iter 430500 | LR: 7.9767372614334e-05 | Loss: 0.4366413286700842
Iter 431000 | LR: 7.949358219528073e-05 | Loss: 0.4412373999133709
Iter 431500 | LR: 7.922037782764099e-05 | Loss: 0.43914513912051917
Iter 432000 | LR: 7.894776138392688e-05 | Loss: 0.4424038777500394
Iter 432500 | LR: 7.867573473262106e-05 | Loss: 0.4438912694528696
Iter 433000 | LR: 7.840429973816367e-05 | Loss: 0.4440657350420949
Iter 433500 | LR: 7.813345826093983e-05 | Loss: 0.4448295680060988
Iter 434000 | LR: 7.786321215726665e-05 | Loss: 0.4456278861314055
Iter 434500 | LR: 7.759356327938075e-05 | Loss: 0.44733788970857885
Iter 435000 | Perplexity: 42.581912994384766
Iter 435000 | LR: 7.732451347542522e-05 | Loss: 0.45485970310866847
Iter 435500 | LR: 7.705606458943737e-05 | Loss: 0.4566282734647393
Iter 436000 | LR: 7.678821846133576e-05 | Loss: 0.4516764378547666
Iter 436500 | LR: 7.652097692690782e-05 | Loss: 0.45183303833007826
Iter 437000 | LR: 7.625434181779704e-05 | Loss: 0.4545022758096455
Iter 437500 | LR: 7.59883149614907e-05 | Loss: 0.4555516052991151
Iter 438000 | LR: 7.572289818130702e-05 | Loss: 0.45466984096914514
Iter 438500 | LR: 7.545809329638282e-05 | Loss: 0.45483117394149314
Iter 439000 | LR: 7.519390212166129e-05 | Loss: 0.4623181176185609
Iter 439500 | LR: 7.4930326467879e-05 | Loss: 0.46084720946848373
Iter 440000 | Perplexity: 42.79169845581055
Iter 440000 | LR: 7.466736814155417e-05 | Loss: 0.4584712018445137
Iter 440500 | LR: 7.440502894497351e-05 | Loss: 0.460052085109055
Iter 441000 | LR: 7.414331067618062e-05 | Loss: 0.4633637843281028
Iter 441500 | LR: 7.388221512896314e-05 | Loss: 0.461498128734529
Iter 442000 | LR: 7.362174409284082e-05 | Loss: 0.4622889579087497
Iter 442500 | LR: 7.336189935305285e-05 | Loss: 0.46088932700455193
Iter 443000 | LR: 7.310268269054608e-05 | Loss: 0.46200709123164424
Iter 443500 | LR: 7.284409588196248e-05 | Loss: 0.4642259225621816
Iter 444000 | LR: 7.258614069962701e-05 | Loss: 0.46499761518090965
Iter 444500 | LR: 7.23288189115357e-05 | Loss: 0.46464146308600884
Iter 445000 | Perplexity: 42.35706329345703
Iter 445000 | LR: 7.207213228134318e-05 | Loss: 0.4724303481727836
Iter 445500 | LR: 7.181608256835098e-05 | Loss: 0.4634277997910979
Iter 446000 | LR: 7.15606715274951e-05 | Loss: 0.46882752627134355
Iter 446500 | LR: 7.13059009093342e-05 | Loss: 0.46515061214566245
Iter 447000 | LR: 7.105177246003757e-05 | Loss: 0.47046364963054677
Iter 447500 | LR: 7.07982879213732e-05 | Loss: 0.4659055707231165
Iter 448000 | LR: 7.054544903069565e-05 | Loss: 0.47130040735006345
Iter 448500 | LR: 7.029325752093447e-05 | Loss: 0.4733424897119406
Iter 449000 | LR: 7.004171512058199e-05 | Loss: 0.46815753448754527
Iter 449500 | LR: 6.979082355368164e-05 | Loss: 0.4701777695491909
Iter 450000 | Perplexity: 42.336952209472656
Iter 450000 | LR: 6.954058453981609e-05 | Loss: 0.47230657055974
Iter 450500 | LR: 6.929099979409557e-05 | Loss: 0.47555182464420814
Iter 451000 | LR: 6.9042071027146e-05 | Loss: 0.46807583734393116
Iter 451500 | LR: 6.879379994509727e-05 | Loss: 0.4772004512324933
Iter 452000 | LR: 6.854618824957157e-05 | Loss: 0.47236015789210783
Iter 452500 | LR: 6.829923763767167e-05 | Loss: 0.47459755323827285
Iter 453000 | LR: 6.805294980196951e-05 | Loss: 0.4740920061618092
Iter 453500 | LR: 6.780732643049427e-05 | Loss: 0.477732263058424
Iter 454000 | LR: 6.75623692067211e-05 | Loss: 0.47516490891575847
Iter 454500 | LR: 6.731807980955935e-05 | Loss: 0.47788336586207164
Iter 455000 | Perplexity: 42.18880081176758
Iter 455000 | LR: 6.707445991334119e-05 | Loss: 0.4773911230266095
Iter 455500 | LR: 6.68315111878101e-05 | Loss: 0.4769774401932957
Iter 456000 | LR: 6.658923529810947e-05 | Loss: 0.4778223127126693
Iter 456500 | LR: 6.634763390477106e-05 | Loss: 0.48113046366721396
Epoch 17.0
Iter 457000 | LR: 6.610670866370387e-05 | Loss: 0.45846226658672146
Iter 457500 | LR: 6.586646122618247e-05 | Loss: 0.41695846229791594
Iter 458000 | LR: 6.562689323883586e-05 | Loss: 0.4150022725760938
Iter 458500 | LR: 6.538800634363627e-05 | Loss: 0.4203858645632859
Iter 459000 | LR: 6.514980217788767e-05 | Loss: 0.4219308028370145
Iter 459500 | LR: 6.491228237421481e-05 | Loss: 0.42041915059089685
Iter 460000 | Perplexity: 46.326995849609375
Iter 460000 | LR: 6.467544856055175e-05 | Loss: 0.4267175120487806
Iter 460500 | LR: 6.443930236013106e-05 | Loss: 0.4215850514546038
Iter 461000 | LR: 6.420384539147218e-05 | Loss: 0.42425405107438563
Iter 461500 | LR: 6.396907926837092e-05 | Loss: 0.42920584142208096
Iter 462000 | LR: 6.373500559988794e-05 | Loss: 0.4326394187286496
Iter 462500 | LR: 6.350162599033806e-05 | Loss: 0.43040253918617977
Iter 463000 | LR: 6.32689420392789e-05 | Loss: 0.4283842058107263
Traceback (most recent call last):
{'deploy': True, 'tag': 'minLM', 'run_name': 'run2', 'seed': 0, 'device': 'cuda:0', 'total_iters': 600000, 'data': {'train_file': 'data/wikitext103/wikitext103_train.json', 'val_file': 'data/wikitext103/wikitext103_validation.json', 'bs': 32, 'nworkers': 2, 'title': False}, 'net': {'compile': True, 'context_size': 1024, 'n_layer': 12, 'n_head': 12, 'n_embd': 1080, 'bias': False, 'dropout': 0.0, 'position_encoding': 'learnable'}, 'optimizer': {'learning_rate': 0.0001, 'min_lr': 1e-05, 'beta1': 0.9, 'beta2': 0.95, 'grad_clip': 1.0, 'weight_decay': 0.1, 'grad_accumulation': 20, 'use_scaler': True, 'warmup_iters': 0, 'decay_lr': True}, 'log': {'eval_interval': 5000, 'log_interval': 500, 'save_interval': 100000}}
hjohcd38
Error executing job with overrides: ['deploy=True']
Traceback (most recent call last):
  File "/home/ubuntu/minLM/train.py", line 16, in main
    trainloader = wikitext103_loader(cfg, train=True)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/minLM/utils/data.py", line 39, in wikitext103_loader
    ds = TextTrainDataset(fname, cfg.net.context_size)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/minLM/utils/data.py", line 19, in __init__
    self.doc = np.memmap(filename, dtype=np.uint16, mode='r', shape=(self.doc_len,))
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/micromamba/envs/minLM/lib/python3.12/site-packages/numpy/core/memmap.py", line 268, in __new__
    mm = mmap.mmap(fid.fileno(), bytes, access=acc, offset=start)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: mmap length is greater than file size

Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.
